"""
ì»¤í”¼ ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸ ë©”ì¸ ì‹¤í–‰ íŒŒì¼

Entmax ì–´í…ì…˜ì„ í™œìš©í•œ LSTM ê¸°ë°˜ ì»¤í”¼ ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸ì˜ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
"""

import pandas as pd
import torch
import torch.nn as nn
import argparse
import numpy as np
import os

# ë¡œì»¬ ëª¨ë“ˆ import (ì ˆëŒ€ importë¡œ ë³€ê²½)
try:
    # íŒ¨í‚¤ì§€ë¡œ ì‹¤í–‰ë  ë•Œ
    from .utils import get_device
    from .preprocessor import preprocess_data, split_and_scale
    from .dataset import MultiStepTimeSeriesDataset
    from .models import AttentionLSTMModel
    from .trainer import train_model, predict_and_inverse, predict_future, evaluate_and_save
    from .visualizer import plot_loss, plot_prediction
    from .data_loader import save_result
    from .trainer import predict_long_future
    from .coffee_price_fetcher import enhance_predictions_with_actual_prices
except ImportError:
    # ì§ì ‘ ì‹¤í–‰ë  ë•Œ
    from utils import get_device
    from preprocessor import preprocess_data, split_and_scale
    from dataset import MultiStepTimeSeriesDataset
    from models import AttentionLSTMModel
    from trainer import train_model, predict_and_inverse, predict_future, evaluate_and_save
    from visualizer import plot_loss, plot_prediction
    from data_loader import save_result
    from trainer import predict_long_future
    from coffee_price_fetcher import enhance_predictions_with_actual_prices


def parse_arguments():
    """
    ëª…ë ¹í–‰ ì¸ìˆ˜ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤.
    
    Returns:
        argparse.Namespace: íŒŒì‹±ëœ ì¸ìˆ˜ë“¤
    """
    parser = argparse.ArgumentParser(description='ì»¤í”¼ ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸ ì‹¤í–‰')
    
    # ë°ì´í„° ê´€ë ¨ íŒŒë¼ë¯¸í„°
    parser.add_argument('--window', type=int, default=100, 
                       help='ì…ë ¥ ì‹œí€€ìŠ¤ ê¸¸ì´ (ê¸°ë³¸ê°’: 100)')
    parser.add_argument('--horizon', type=int, default=14, 
                       help='ì˜ˆì¸¡ êµ¬ê°„ ê¸¸ì´ (ê¸°ë³¸ê°’: 14)')
    parser.add_argument('--step', type=int, default=1, 
                       help='ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ìŠ¤í… í¬ê¸° (ê¸°ë³¸ê°’: 1)')
    
    # ëª¨ë¸ ê´€ë ¨ íŒŒë¼ë¯¸í„°
    parser.add_argument('--hidden_size', type=int, default=64, 
                       help='LSTM ì€ë‹‰ ìƒíƒœ í¬ê¸° (ê¸°ë³¸ê°’: 64)')
    parser.add_argument('--num_layers', type=int, default=2, 
                       help='LSTM ë ˆì´ì–´ ìˆ˜ (ê¸°ë³¸ê°’: 2)')
    parser.add_argument('--dropout', type=float, default=0.1, 
                       help='ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.1)')
    
    # í•™ìŠµ ê´€ë ¨ íŒŒë¼ë¯¸í„°
    parser.add_argument('--epochs', type=int, default=5, 
                       help='í•™ìŠµ ì—í¬í¬ ìˆ˜ (ê¸°ë³¸ê°’: 5)')
    parser.add_argument('--batch_size', type=int, default=64, 
                       help='í›ˆë ¨ ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: 64)')
    parser.add_argument('--test_batch_size', type=int, default=32, 
                       help='í…ŒìŠ¤íŠ¸ ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: 32)')
    parser.add_argument('--lr', type=float, default=0.001, 
                       help='í•™ìŠµë¥  (ê¸°ë³¸ê°’: 0.001)')
    parser.add_argument('--alpha', type=float, default=0.2, 
                       help='ë°©í–¥ì„± ì†ì‹¤ ê°€ì¤‘ì¹˜ (ê¸°ë³¸ê°’: 0.2)')
    parser.add_argument('--beta', type=float, default=0.1, 
                       help='ë¶„ì‚° ì†ì‹¤ ê°€ì¤‘ì¹˜ (ê¸°ë³¸ê°’: 0.1)')
    
    # ê¸°íƒ€ íŒŒë¼ë¯¸í„°
    parser.add_argument('--no_plot', action='store_true', 
                       help='ì‹œê°í™” ìƒëµ')
    parser.add_argument('--device', type=str, default='auto', 
                       choices=['auto', 'cpu', 'cuda'], 
                       help='ì‚¬ìš©í•  ì¥ì¹˜ (ê¸°ë³¸ê°’: auto)')
    parser.add_argument('--examples', action='store_true', 
                       help='ì‚¬ìš© ì˜ˆì‹œ ì¶œë ¥ í›„ ì¢…ë£Œ')
    
    args = parser.parse_args()
    
    # ì‚¬ìš© ì˜ˆì‹œ ì¶œë ¥ í›„ ì¢…ë£Œ
    if args.examples:
        print_usage_examples()
        exit(0)
    
    return args


def print_usage_examples():
    """
    ì‚¬ìš© ì˜ˆì‹œë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    print("\n=== ì‚¬ìš© ì˜ˆì‹œ ===")
    print("1. ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì‹¤í–‰:")
    print("   python run_model.py")
    print()
    print("2. ì—í¬í¬ ìˆ˜ì™€ ìœˆë„ìš° í¬ê¸° ë³€ê²½:")
    print("   python run_model.py --epochs 10 --window 50")
    print()
    print("3. ëª¨ë¸ êµ¬ì¡° ë³€ê²½:")
    print("   python run_model.py --hidden_size 128 --num_layers 3 --dropout 0.2")
    print()
    print("4. í•™ìŠµ ì„¤ì • ë³€ê²½:")
    print("   python run_model.py --batch_size 32 --lr 0.0001 --alpha 0.3 --beta 0.15")
    print()
    print("5. ì‹œê°í™” ì—†ì´ ì‹¤í–‰:")
    print("   python run_model.py --no_plot")
    print()
    print("6. CPU ê°•ì œ ì‚¬ìš©:")
    print("   python run_model.py --device cpu")
    print()
    print("7. ì „ì²´ ì˜µì…˜ í™•ì¸:")
    print("   python run_model.py --help")
    print()


def main():
    """
    ì»¤í”¼ ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸ì˜ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    
    ì£¼ìš” ë‹¨ê³„:
    1. ëª…ë ¹í–‰ ì¸ìˆ˜ íŒŒì‹±
    2. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
    3. ë°ì´í„° ë¶„í•  ë° ì •ê·œí™”
    4. ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìƒì„±
    5. ëª¨ë¸ ì´ˆê¸°í™” ë° í•™ìŠµ
    6. í…ŒìŠ¤íŠ¸ êµ¬ê°„ ì˜ˆì¸¡
    7. ë¯¸ë˜ êµ¬ê°„ ì˜ˆì¸¡
    8. ê²°ê³¼ í‰ê°€ ë° ì €ì¥
    """
    # 1. ëª…ë ¹í–‰ ì¸ìˆ˜ íŒŒì‹±
    args = parse_arguments()
    
    print("=== ì»¤í”¼ ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸ ì‹œì‘ ===")
    print(f"ì„¤ì •ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°:")
    print(f"  - ìœˆë„ìš° í¬ê¸°: {args.window}")
    print(f"  - ì˜ˆì¸¡ êµ¬ê°„: {args.horizon}")
    print(f"  - ì—í­ ìˆ˜: {args.epochs}")
    print(f"  - ë°°ì¹˜ í¬ê¸°: {args.batch_size}")
    print(f"  - í•™ìŠµë¥ : {args.lr}")
    print(f"  - ì€ë‹‰ í¬ê¸°: {args.hidden_size}")
    print(f"  - LSTM ë ˆì´ì–´: {args.num_layers}")
    
    # 2. í™˜ê²½ ì„¤ì •
    if args.device == 'auto':
        device = get_device()
    else:
        device = args.device
    print(f"ì‚¬ìš© ì¥ì¹˜: {device}")
    
    # 3. ë°ì´í„° ì „ì²˜ë¦¬
    print("ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
    df = preprocess_data()
    print(f"ì „ì²˜ë¦¬ëœ ë°ì´í„° í¬ê¸°: {df.shape}")
    
    # 4. ê³ ì • íŒŒë¼ë¯¸í„° ì„¤ì •
    target_col = "Coffee_Price_Return"
    price_col = "Coffee_Price"
    static_feat_count = 9
    
    # 5. ë°ì´í„° ë¶„í•  ë° ì •ê·œí™”
    print("ë°ì´í„° ë¶„í•  ë° ì •ê·œí™” ì¤‘...")
    X_train, y_train, X_test, y_test, train_df, test_df, scaler, static_feat_idx = split_and_scale(
        df, target_col, static_feat_count, args.window, args.horizon, args.step
    )
    
    # 6. ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìƒì„±
    train_dataset = MultiStepTimeSeriesDataset(X_train, y_train, args.window, args.horizon, args.step, static_feat_idx)
    test_dataset = MultiStepTimeSeriesDataset(X_test, y_test, args.window, args.horizon, args.step, static_feat_idx)
    
    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)
    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.test_batch_size, shuffle=False)
    
    print(f"í›ˆë ¨ ë°ì´í„°ì…‹ í¬ê¸°: {len(train_dataset)}")
    print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ í¬ê¸°: {len(test_dataset)}")
    
    # 7. ëª¨ë¸ ì´ˆê¸°í™”
    x_seq, x_static, _ = train_dataset[0]
    input_size = x_seq.shape[1]
    static_feat_dim = x_static.shape[0]
    
    model = AttentionLSTMModel(
        input_size=input_size, 
        hidden_size=args.hidden_size,
        num_layers=args.num_layers,
        target_size=args.horizon, 
        dropout=args.dropout,
        static_feat_dim=static_feat_dim
    ).to(device)
    
    print(f"ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in model.parameters()):,}")
    
    # 8. í•™ìŠµ ì„¤ì •
    base_criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.3, patience=10)
    
    # 9. ëª¨ë¸ í•™ìŠµ
    print("ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    train_losses, test_losses = train_model(
        model, train_loader, test_loader, base_criterion, optimizer, scheduler, 
        args.epochs, args.alpha, args.beta, device
    )
    
    # 10. í•™ìŠµ ê³¡ì„  ì‹œê°í™”
    if not args.no_plot:
        plot_loss(train_losses, test_losses)
    
    # 11. í…ŒìŠ¤íŠ¸ êµ¬ê°„ ì˜ˆì¸¡
    print("í…ŒìŠ¤íŠ¸ êµ¬ê°„ ì˜ˆì¸¡ ì¤‘...")
    forecast_all, predictions = predict_and_inverse(
        model, test_loader, scaler, train_df, test_df, df, target_col, 
        price_col, args.window, args.horizon, args.step, static_feat_idx
    )
    
    # 12. í…ŒìŠ¤íŠ¸ êµ¬ê°„ ê²°ê³¼ ì‹œê°í™”
    if not args.no_plot:
        plot_prediction(df, forecast_all, start=pd.to_datetime('2023-07-01'), end=pd.to_datetime('2025-04-01'))
    
    # 13. ë¯¸ë˜ êµ¬ê°„ ì˜ˆì¸¡
    print("ë¯¸ë˜ êµ¬ê°„ ì˜ˆì¸¡ ì¤‘...")
    future_price_series, future_dates, price_future = predict_future(
        model, test_df, train_df, scaler, static_feat_idx, args.window, 
        args.horizon, price_col, target_col
    )
    
    # 14. ì „ì²´ ê²°ê³¼ ì‹œê°í™” (í…ŒìŠ¤íŠ¸ + ë¯¸ë˜)
    if not args.no_plot:
        plot_prediction(
            df, forecast_all, 
            start=pd.to_datetime('2023-07-01'), 
            end=future_price_series.index[-1], 
            future_series=future_price_series
        )
    
    # 15. ê²°ê³¼ í‰ê°€ ë° ì €ì¥
    print("ê²°ê³¼ í‰ê°€ ë° ì €ì¥ ì¤‘...")
    evaluate_and_save(df, forecast_all, predictions, price_col, future_dates, price_future)
    
    print("=== ì»¤í”¼ ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸ ì™„ë£Œ ===")

    # 16. ì „ì²´ ë°ì´í„°ë¡œ ì¬í•™ìŠµ ë° 1ë…„ ì˜ˆì¸¡/ì €ì¥
    print("\n[ì¶”ê°€ ê¸°ëŠ¥] ì „ì²´ ë°ì´í„°ë¡œ ì¬í•™ìŠµ ë° 1ë…„ ì˜ˆì¸¡/ì €ì¥ ì‹œì‘...")
    # ì „ì²´ ë°ì´í„°ì…‹ ì¤€ë¹„
    X_all = np.concatenate([X_train, X_test], axis=0)
    y_all = np.concatenate([y_train, y_test], axis=0)
    all_df = pd.concat([train_df, test_df], axis=0)
    all_df = all_df.loc[~all_df.index.duplicated(keep='first')]
    all_dataset = MultiStepTimeSeriesDataset(X_all, y_all, args.window, args.horizon, args.step, static_feat_idx)
    all_loader = torch.utils.data.DataLoader(all_dataset, batch_size=args.batch_size, shuffle=True)

    # ìƒˆ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    model_all = AttentionLSTMModel(
        input_size=input_size,
        hidden_size=args.hidden_size,
        num_layers=args.num_layers,
        target_size=args.horizon,
        dropout=args.dropout,
        static_feat_dim=static_feat_dim
    ).to(device)
    optimizer_all = torch.optim.Adam(model_all.parameters(), lr=args.lr)
    scheduler_all = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_all, mode='min', factor=0.3, patience=10)
    base_criterion_all = nn.MSELoss()

    # ì¬í•™ìŠµ
    print("ì „ì²´ ë°ì´í„°ë¡œ ëª¨ë¸ ì¬í•™ìŠµ ì¤‘...")
    train_model(
        model_all, all_loader, all_loader, base_criterion_all, optimizer_all, scheduler_all,
        args.epochs, args.alpha, args.beta, device
    )

    # ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€ 1ë…„(365ì¼) ì˜ˆì¸¡
    print("1ë…„ ì¥ê¸° ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...")
    try:
        future_price_series_long, future_dates_long, price_future_long = predict_long_future(
            model_all, all_df, scaler, static_feat_idx, args.window, 365, args.horizon, price_col, target_col
        )

        # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì˜¬ë°”ë¥¸ ë‚ ì§œ ì¸ë±ìŠ¤ë¡œ ì„¤ì •
        start_date = all_df.index[-1] + pd.Timedelta(days=1)
        future_price_series_long.index = pd.date_range(start=start_date, periods=len(future_price_series_long), freq='D')

        # 1ë…„ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë³„ë„ íŒŒì¼ë¡œ ì €ì¥ (ì‹¤ì œ ê°€ê²© í¬í•¨)
        print("1ë…„ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì¤‘...")
        
        current_dir = os.path.dirname(os.path.abspath(__file__))
        app_dir = os.path.abspath(os.path.join(current_dir, '../../../'))
        output_dir = os.path.join(app_dir, 'data', 'output')
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
        os.makedirs(output_dir, exist_ok=True)
        
        # 1ë…„ ì˜ˆì¸¡ ê²°ê³¼ DataFrame ìƒì„±
        future_df_1year = pd.DataFrame({
            "Date": future_price_series_long.index,
            "Predicted_Price": future_price_series_long.values,
            "Actual_Price": [None] * len(future_price_series_long)
        })
        
        # ì‹¤ì œ ì»¤í”¼ ê°€ê²© ì¶”ê°€
        if enhance_predictions_with_actual_prices is not None:
            try:
                future_df_1year = enhance_predictions_with_actual_prices(future_df_1year)
            except Exception as e:
                print(f"âš ï¸ ì‹¤ì œ ê°€ê²© ì¶”ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                print("ì˜ˆì¸¡ê°’ë§Œ ì €ì¥í•©ë‹ˆë‹¤.")
        
        # íŒŒì¼ ì €ì¥
        future_1year_path = os.path.join(output_dir, 'prediction_result_future_1year.csv')
        future_df_1year.to_csv(future_1year_path, index=False)
        print(f"1ë…„ ì˜ˆì¸¡ ê²°ê³¼ê°€ {future_1year_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ì‹¤ì œ ê°€ê²©ì´ ì¶”ê°€ëœ ë‚ ì§œ ìˆ˜ ì¶œë ¥
        actual_price_count = future_df_1year['Actual_Price'].notna().sum()
        total_predictions = len(future_df_1year)
        print(f"ğŸ“Š ì´ {total_predictions}ê°œ ì˜ˆì¸¡ ì¤‘ {actual_price_count}ê°œ ë‚ ì§œì— ì‹¤ì œ ê°€ê²© í¬í•¨")
        
        print("[ì¶”ê°€ ê¸°ëŠ¥] ì „ì²´ ë°ì´í„° ì¬í•™ìŠµ ë° 1ë…„ ì˜ˆì¸¡/ì €ì¥ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"ì¥ê¸° ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("ë‹¨ê¸° ì˜ˆì¸¡ ê²°ê³¼ëŠ” ì •ìƒì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 