"""
LSTM + Attention + Entmax ëª¨ë¸ì„ ì´ìš©í•œ ì»¤í”¼ ìƒë‘ ê°€ê²© ì˜ˆì¸¡ ëª¨ë“ˆ

ì‹¤í–‰ ë°©ë²•:
python -m src.models.lstm_attention.run_model --loss_fn mse --epochs 10
"""

import os
import sys
import torch
import numpy as np
import time
import argparse
import warnings
warnings.filterwarnings('ignore')

# íŒ¨í‚¤ì§€ ê²½ë¡œ ì„¤ì •
current_dir = os.path.dirname(os.path.abspath(__file__))
app_dir = os.path.abspath(os.path.join(current_dir, '../../../'))
if app_dir not in sys.path:
    sys.path.append(app_dir)

# íŒ¨í‚¤ì§€ êµ¬ì¡°ì— ë§ëŠ” ìƒëŒ€ import
from .data_preprocessor import *
from .model import *
from .utils import *
from .debug import *

def parse_arguments():
    """ëª…ë ¹ì¤„ ì¸ì íŒŒì‹± í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='ì»¤í”¼ ìƒë‘ ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸ë§')
    
    # ì†ì‹¤ í•¨ìˆ˜ ì„ íƒ (mse ë˜ëŠ” huber)
    parser.add_argument('--loss_fn', type=str, default='mse', choices=['mse', 'huber'],
                        help='ì†ì‹¤ í•¨ìˆ˜ ìœ í˜• (mse ë˜ëŠ” huber)')
    
    # Huber lossì˜ delta ê°’ ì„¤ì • (huber loss ì‚¬ìš© ì‹œì—ë§Œ ì ìš©)
    parser.add_argument('--delta', type=float, default=1.0,
                        help='Huber lossì˜ delta ê°’ (huber loss ì‚¬ìš© ì‹œì—ë§Œ ì ìš©)')
    
    # í›ˆë ¨ ì—í­ ìˆ˜ ì„¤ì •
    parser.add_argument('--epochs', type=int, default=5,
                        help='í›ˆë ¨ ì—í­ ìˆ˜')
    
    # í•™ìŠµë¥  ì„¤ì •
    parser.add_argument('--lr', type=float, default=0.001,
                        help='í•™ìŠµë¥ ')
    
    parser.add_argument('--online', action='store_true',
                    help='ì˜¨ë¼ì¸ ì—…ë°ì´íŠ¸ ë°©ì‹ìœ¼ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰')

    return parser.parse_args()

def main(loss_fn='mse', delta=1.0, epochs=5, lr=0.001, online=False):
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    
    Args:
        loss_fn (str): ì†ì‹¤ í•¨ìˆ˜ ìœ í˜• ('mse' ë˜ëŠ” 'huber')
        delta (float): Huber ì†ì‹¤ í•¨ìˆ˜ì˜ delta ê°’ (huber ì‚¬ìš© ì‹œì—ë§Œ ì ìš©)
        epochs (int): í›ˆë ¨ ì—í­ ìˆ˜
        lr (float): í•™ìŠµë¥ 
    
    Returns:
        dict: ëª¨ë¸ë§ ê²°ê³¼
    """
    try:
        start_time = time.time()
        print(f"ğŸš€ ì»¤í”¼ ìƒë‘ ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸ë§ ì‹œì‘")
        print(f"ğŸ“Š ì„¤ì • - ì†ì‹¤ í•¨ìˆ˜: {loss_fn}, Delta: {delta}, ì—í­: {epochs}, í•™ìŠµë¥ : {lr}")
        
        # 1. ë°ì´í„° ë¡œë“œ
        weather_data = load_weather_data()
        weather_data = remove_lag(weather_data)
        
        # 2. ë°ì´í„° ì „ì²˜ë¦¬
        weather_data = leave_PRECTOTCORR_columns(weather_data)  # ê¸°í›„ ë°ì´í„° ì¤‘ì—ì„œ ê°•ìˆ˜ëŸ‰ + í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ë‚¨ê¹€
        
        # 3. ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”© í›„ ë³€ë™ì„± ê´€ë ¨ íŒŒìƒ í”¼ì²˜ ì¶”ê°€
        weather_data = encode_categorical_features(weather_data)  # ë¨¼ì € ë²”ì£¼í˜• ì¸ì½”ë”©
        weather_data = add_volatility_features(weather_data)      # ê·¸ ë‹¤ìŒ ë³€ë™ì„± íŠ¹ì„± ì¶”ê°€
        
        # 4. train/test split
        train_data, test_data = split_data(weather_data, train_ratio=0.8)  # 80% train, 20% test
        
        # 5. ë°ì´í„° í˜•íƒœ ë””ë²„ê¹… (None ì²´í¬ê°€ ìˆëŠ” í•¨ìˆ˜ ì‚¬ìš©)
        debug_data_shape(train_data, test_data)  # ë¡œë”ëŠ” ì•„ì§ ì—†ìœ¼ë¯€ë¡œ ì¸ì ì œê±°
        
        # 6. ë°ì´í„° ì¤€ë¹„
        train_loader, test_loader, scaler, test_dates, seq_length, pred_length = prepare_data_for_model(train_data, test_data)
        
        # ì´ì œ ë¡œë”ê°€ ì¤€ë¹„ë˜ì—ˆìœ¼ë¯€ë¡œ ë” ìì„¸í•œ ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
        debug_data_shape(train_data, test_data, train_loader, test_loader)
        
        # 7. ëª¨ë¸ ì„¤ì • - Softmax Attention ëª¨ë¸ ì‚¬ìš©
        input_dim = train_data.shape[1]  # íŠ¹ì„± ê°œìˆ˜
        model, device = setup_model(input_dim, use_entmax=False)
        
        # 8. ëª¨ë¸ í›ˆë ¨ - ìˆ˜ì •ëœ íŒŒë¼ë¯¸í„° ì‚¬ìš©
        train_losses, val_losses = train_model(
            model, 
            train_loader, 
            test_loader, 
            epochs=epochs,          # íŒŒë¼ë¯¸í„°ë¡œ ì „ë‹¬ë°›ì€ ì—í­ ìˆ˜ ì‚¬ìš©
            lr=lr,                  # íŒŒë¼ë¯¸í„°ë¡œ ì „ë‹¬ë°›ì€ í•™ìŠµë¥  ì‚¬ìš©
            device=device, 
            loss_fn_type=loss_fn,   # íŒŒë¼ë¯¸í„°ë¡œ ì „ë‹¬ë°›ì€ ì†ì‹¤ í•¨ìˆ˜ ì‚¬ìš©
            delta=delta             # íŒŒë¼ë¯¸í„°ë¡œ ì „ë‹¬ë°›ì€ delta ê°’ ì‚¬ìš©
        )
        
        # 9. ëª¨ë¸ í‰ê°€
        if online:
            print("ğŸ”„ ì˜¨ë¼ì¸ ì—…ë°ì´íŠ¸ ë°©ì‹ìœ¼ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...")

            test_data_array = test_data.values if hasattr(test_data, 'values') else test_data

            predictions, actuals = online_update_prediction(
                model=model,
                test_data=scaler.transform(test_data_array),
                scaler=scaler,
                seq_length=seq_length,
                pred_length=pred_length,
                device=device,
                lr=lr,
                loss_fn=loss_fn
            )

            attention_weights = None  # ì˜¨ë¼ì¸ ë°©ì‹ì—ì„œëŠ” attention ì €ì¥í•˜ì§€ ì•ŠìŒ
            mae = np.mean(np.abs(predictions.flatten() - actuals.flatten()))
            rmse = np.sqrt(np.mean((predictions.flatten() - actuals.flatten())**2))

        else:
            predictions, actuals, attention_weights, mae, rmse = predict_and_evaluate(
                model, test_loader, scaler, device
            )
        
        # 10. ê²°ê³¼ ì €ì¥ - í´ë” ìƒì„± ë° ê²°ê³¼ ì €ì¥
        # ì €ì¥ í´ë” ì´ë¦„ ìƒì„±: loss í•¨ìˆ˜ ë° ì—í­ ì •ë³´ í¬í•¨
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        folder_name = f"coffee_price_model_{loss_fn}_epochs{epochs}_{timestamp}"
        
        # 11. ëª¨ë¸ ë° ê²°ê³¼ ì €ì¥
        result_dir = save_model_results(
            model, 
            train_losses, 
            val_losses, 
            predictions, 
            actuals, 
            test_dates=test_dates,
            folder_name=folder_name
        )
        
        # 12. ì„±ëŠ¥ ìš”ì•½ ì‹œê°í™” - ë™ì¼í•œ í´ë”ì— ì €ì¥
        visualization_summary(
            predictions, 
            actuals, 
            train_losses, 
            val_losses, 
            mae, 
            rmse, 
            test_dates=test_dates,
            folder_name=folder_name
        )
        
        # 13. ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì˜ˆì¸¡ (ì„ íƒì )
        # ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìœ¼ë¯€ë¡œ í•„ìš”í•œ ê²½ìš°ì—ë§Œ ì‹¤í–‰
        run_sliding = True
        if run_sliding:
            try:
                test_data_array = test_data.values if hasattr(test_data, 'values') else test_data
                sliding_predictions = run_sliding_window_prediction(
                    model, 
                    scaler.transform(test_data_array), 
                    scaler, 
                    seq_length, 
                    pred_length, 
                    device
                )
                
                # ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”
                plot_sliding_window_predictions(
                    sliding_predictions, 
                    max_samples=5, 
                    save_path=os.path.join(result_dir, 'sliding_window_predictions.png')
                )
            except Exception as e:
                print(f"âš ï¸ ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        elapsed_time = time.time() - start_time
        print(f"ğŸ ëª¨ë¸ë§ ì™„ë£Œ - ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
        print(f"ğŸ“‚ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {result_dir}")
        
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì •ë³´ ì €ì¥
        hyperparams = {
            'loss_function': loss_fn,
            'delta': delta if loss_fn == 'huber' else 'N/A',
            'epochs': epochs,
            'learning_rate': lr,
            'mae': mae,
            'rmse': rmse
        }
        
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° íŒŒì¼ ì €ì¥
        with open(os.path.join(result_dir, 'hyperparameters.txt'), 'w') as f:
            for param, value in hyperparams.items():
                f.write(f"{param}: {value}\n")
        
        return {
            'model': model,
            'train_losses': train_losses,
            'val_losses': val_losses,
            'predictions': predictions,
            'actuals': actuals,
            'attention_weights': attention_weights,
            'mae': mae,
            'rmse': rmse,
            'scaler': scaler,
            'hyperparams': hyperparams
        }
    
    except Exception as e:
        import traceback
        print(f"âŒ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(traceback.format_exc())
        return None

if __name__ == "__main__":
    # ëª…ë ¹ì¤„ ì¸ì íŒŒì‹±
    args = parse_arguments()
    
    # ëª¨ë¸ë§ ì‹¤í–‰ (ëª…ë ¹ì¤„ ì¸ì ì‚¬ìš©)
    results = main(
        loss_fn=args.loss_fn,
        delta=args.delta,
        epochs=args.epochs,
        lr=args.lr,
        online=args.online
    )