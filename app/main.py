from fastapi import FastAPI, Query
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from contextlib import asynccontextmanager
import pandas as pd
import numpy as np
import sys
import os
import subprocess
from datetime import datetime


def setup_entmax_model_path():
    """LSTM-Entmax ëª¨ë¸ ê²½ë¡œë¥¼ sys.pathì— ì¶”ê°€"""
    current_dir = os.path.dirname(os.path.abspath(__file__))
    lstm_entmax_path = os.path.join(current_dir, "models", "time_series", "lstm-entmax")
    if lstm_entmax_path not in sys.path:
        sys.path.append(lstm_entmax_path)


def run_entmax_model(epochs=5, lr=0.001, window=100, horizon=14, hidden_size=64, num_layers=2):
    """LSTM-Entmax ëª¨ë¸ì„ ì‹¤í–‰í•˜ëŠ” í•¨ìˆ˜"""
    setup_entmax_model_path()
    
    run_model_path = os.path.join(os.path.dirname(__file__), "models", "time_series", "lstm-entmax", "run_model.py")
    
    cmd = [
        sys.executable, run_model_path,
        '--epochs', str(epochs),
        '--lr', str(lr),
        '--window', str(window),
        '--horizon', str(horizon),
        '--hidden_size', str(hidden_size),
        '--num_layers', str(num_layers),
        '--no_plot'  # ì„œë²„ì—ì„œëŠ” ì‹œê°í™” ë¹„í™œì„±í™”
    ]
    
    print(f"ğŸš€ ëª¨ë¸ ì‹¤í–‰ ëª…ë ¹ì–´: {' '.join(cmd)}")
    
    # subprocessë¡œ ì‹¤í–‰
    result = subprocess.run(cmd, capture_output=True, text=True, cwd=os.path.dirname(__file__))
    
    if result.returncode != 0:
        raise Exception(f"Model execution failed: {result.stderr}")
    
    print("âœ… ëª¨ë¸ ì‹¤í–‰ ì™„ë£Œ")
    print(result.stdout)
    
    return {
        'hyperparams': {
            'model_type': 'LSTM-Entmax',
            'window_size': window,
            'horizon': horizon,
            'epochs': epochs,
            'learning_rate': lr,
            'hidden_size': hidden_size,
            'num_layers': num_layers
        },
        'mae': None,  # run_model.pyì—ì„œ ì§ì ‘ CSVë¡œ ì €ì¥
        'rmse': None
    }

@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì•± ì‹œì‘ ì‹œ ì‹¤í–‰ë˜ëŠ” lifespan ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬"""
    print("\n===== API ì„œë²„ ì‹œì‘ =====")
    print("â³ LSTM-Entmax ëª¨ë¸ ë¡œë“œ ì¤‘...")
    
    # í™˜ê²½ ë³€ìˆ˜ì—ì„œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¡œë“œ
    epochs = int(os.environ.get("COFFEE_MODEL_EPOCHS", "5"))
    lr = float(os.environ.get("COFFEE_MODEL_LR", "0.001"))
    window = int(os.environ.get("COFFEE_MODEL_WINDOW", "100"))
    horizon = int(os.environ.get("COFFEE_MODEL_HORIZON", "14"))
    hidden_size = int(os.environ.get("COFFEE_MODEL_HIDDEN_SIZE", "64"))
    num_layers = int(os.environ.get("COFFEE_MODEL_NUM_LAYERS", "2"))

    print(f"ğŸ“Š ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° - ì—í­: {epochs}, í•™ìŠµë¥ : {lr}, ìœˆë„ìš°: {window}")
    
    model_results = run_entmax_model(epochs, lr, window, horizon, hidden_size, num_layers)
    print("âœ… LSTM-Entmax ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    
    app.state.model_results = model_results
    
    yield
    print("\n===== API ì„œë²„ ì¢…ë£Œ =====")


# FastAPI ì•± ìƒì„±
app = FastAPI(lifespan=lifespan)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

DEV_CSV_PATH = "./data/output/prediction_result.csv"
CSV_PATH = "./data/output/prediction_result_future_1year.csv"

def create_error_response(status_code: int, message: str):
    """ì—ëŸ¬ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    return JSONResponse(
        status_code=status_code,
        content={
            "status": "error",
            "message": message,
            "timestamp": datetime.now().isoformat()
        }
    )


def create_success_response(data=None, message="ì„±ê³µ"):
    """ì„±ê³µ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    content = {
        "status": "success",
        "timestamp": datetime.now().isoformat()
    }
    if data is not None:
        content["data"] = data
    if message != "ì„±ê³µ":
        content["message"] = message
    
    return JSONResponse(status_code=200, content=content)


@app.get("/prediction-dev")
async def get_predictions():
    # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if not os.path.exists(DEV_CSV_PATH):
        return create_error_response(404, "ì˜ˆì¸¡ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    try:
        # API ì‘ë‹µì„ ìœ„í•œ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
        df = pd.read_csv(DEV_CSV_PATH)
        
        if df.empty:
            return create_error_response(500, "ë°ì´í„° íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        
        df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')
        # NaN ê°’ì„ Noneìœ¼ë¡œ ë³€í™˜ (JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ë„ë¡)
        df = df.replace({np.nan: None})
        
        return create_success_response(data=df.to_dict(orient="records"))
        
    except Exception as e:
        return create_error_response(500, f"ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")

@app.get("/prediction")
async def get_predictions():
    # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if not os.path.exists(CSV_PATH):
        return create_error_response(404, "ì˜ˆì¸¡ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    try:
        # API ì‘ë‹µì„ ìœ„í•œ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
        df = pd.read_csv(CSV_PATH)
        
        if df.empty:
            return create_error_response(500, "ë°ì´í„° íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        
        df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')
        # NaN ê°’ì„ Noneìœ¼ë¡œ ë³€í™˜ (JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ë„ë¡)
        df = df.replace({np.nan: None})
        
        return create_success_response(data=df.to_dict(orient="records"))
        
    except Exception as e:
        return create_error_response(500, f"ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")

@app.get("/health")
async def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸ìš© ì—”ë“œí¬ì¸íŠ¸"""
    try:
        # CSV íŒŒì¼ ìƒíƒœë„ í™•ì¸
        file_exists = os.path.exists(CSV_PATH)
        file_status = "available" if file_exists else "missing"
        
        return create_success_response(data={"file_status": file_status})
    except Exception as e:
        return create_error_response(500, f"ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {str(e)}")


@app.get("/model/info")
async def get_model_info():
    """í˜„ì¬ ë¡œë“œëœ ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
    # app.stateì— ëª¨ë¸ ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
    if not hasattr(app.state, 'model_results') or app.state.model_results is None:
        return create_error_response(404, "ëª¨ë¸ ì •ë³´ê°€ ì•„ì§ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    # ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ë° ì„±ëŠ¥ ì§€í‘œ ì¶”ì¶œ
    model_results = app.state.model_results
    hyperparams = model_results.get('hyperparams', {})
    mae = model_results.get('mae', None)
    rmse = model_results.get('rmse', None)
    
    model_info = {
        "hyperparameters": hyperparams,
        "metrics": {
            "mae": float(mae) if mae is not None else None,
            "rmse": float(rmse) if rmse is not None else None
        }
    }
    
    return create_success_response(data={"model_info": model_info})


if __name__ == "__main__":
    import uvicorn
    # í™˜ê²½ ë³€ìˆ˜ì—ì„œ í¬íŠ¸ ê°€ì ¸ì˜¤ê¸° (ê¸°ë³¸ê°’: 8000)
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)